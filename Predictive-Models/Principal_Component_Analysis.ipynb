{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame with the engineered features is imported, along with necessary modules.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "\n",
    "model_df = pd.read_csv('../Data/model_data.csv', index_col = 0)\n",
    "X = model_df.drop(['industry', 'office'], axis = 1)\n",
    "df_columns = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two scaling processes with default parameters will be compared in regards to how they interact with PCA.\n",
    "StandardScaler is a straightforward method but can be more vulnerable to outliers.\n",
    "QuantileTransformer is a more thorough method that tends to punish outliers to a greater extent than other scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20647195 0.20179142 0.1470405  0.12501594 0.12324258 0.08883371\n",
      " 0.05997031 0.04763358]\n",
      "['current_ratio' 'operating_cash_flow' 'debt_to_equity'\n",
      " 'interest_coverage' 'operating_margin' 'return_on_assets'\n",
      " 'return_on_equity' 'has_interest_payments']\n"
     ]
    }
   ],
   "source": [
    "# The features appear to have a more linear distribution in terms of explained variance. This does not necessarily mean that \n",
    "# this better reflects reality, however.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standard = scaler.fit_transform(X)\n",
    "pca_df = pd.DataFrame(X_standard, columns = df_columns)\n",
    "\n",
    "pca = PCA(n_components = 8, svd_solver = 'full')\n",
    "\n",
    "pca.fit(pca_df)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42502874 0.19123835 0.13394252 0.0999914  0.0791696  0.04079046\n",
      " 0.01779352 0.01204541]\n",
      "['current_ratio' 'operating_cash_flow' 'debt_to_equity'\n",
      " 'interest_coverage' 'operating_margin' 'return_on_assets'\n",
      " 'return_on_equity' 'has_interest_payments']\n"
     ]
    }
   ],
   "source": [
    "# With this scaler, the components with greater influence are magnified, and those with less impact are shrunk.\n",
    "# Current ratio in particular is given a very high weighting, followed distantly by operating cash flow and debt to equity.\n",
    "\n",
    "scaler_quantile = QuantileTransformer()\n",
    "X_quantile = scaler_quantile.fit_transform(X)\n",
    "pca_df = pd.DataFrame(X_quantile, columns = df_columns)\n",
    "\n",
    "pca = PCA(n_components = 8, svd_solver = 'full')\n",
    "\n",
    "pca.fit(pca_df)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantile Transformer results in a more decisive PCA, which will ultimately be important when attempting to correctly classify companies using a large set of industries. For that reason I will be using it in my final pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
